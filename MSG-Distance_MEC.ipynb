{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Function will reformat and analyse market data from RAVs in order to dimension the Edge Cloud Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Careful this is the third version\n",
    "def create_clusters(lsee_in, cluster_max,see):\n",
    "    # Initialize variables and set up first comparison\n",
    "    lsee = lsee_in.copy()\n",
    "    # We will use this variable to count towards cluster max size\n",
    "    count = 0\n",
    "    # Use low_see to turn off printing in the sub-routines, but leave it on here\n",
    "    low_see = False\n",
    "    # Use this variable to record the eNB id of the cluster\n",
    "    clusterenb = lsee.get_value(0,'Genid')\n",
    "    start = int(clusterenb)\n",
    "    if see:\n",
    "        print 'Starting clustereNb ', start\n",
    "    if not cluster_max:\n",
    "        cluster_max = 100\n",
    "    if see:\n",
    "        print cluster_max\n",
    "        # Loop to assign cluster keys every cluster_max groups unless they are the same location\n",
    "    row_prev_ = get_lon(lsee,0,low_see)\n",
    "    row_prev = float(row_prev_[1])\n",
    "    ##################################################\n",
    "\n",
    "    df_size = len(lsee.index)\n",
    "    \n",
    "    for i in range(df_size):\n",
    "        count +=1\n",
    "        row_curr_ = get_lon(lsee,i,low_see)\n",
    "        row_curr = float(row_curr_[1])\n",
    "        #rowv_,sindex = get_enb(lsee,i,low_see)\n",
    "        #rowv = int(rowv_[0])\n",
    "        clusterenb = lsee.get_value(i,'clustereNb')\n",
    "        ##################################################\n",
    "        # We could get the distance of the current row to the proposed cluster \n",
    "        # If the distance is beyond a limit, we could force a new cluster, this is overkill since\n",
    "        # others will have a k-means clustering algorithm.\n",
    "        ##################################################\n",
    "        # Check 4 cases \n",
    "        if row_curr == row_prev and count <cluster_max:\n",
    "            #add to cluster by taking genid and setting to clusterenb;\n",
    "            lsee.set_value(i,'clustereNb', start)\n",
    "\n",
    "            if low_see:\n",
    "                print \"Case 1- Same Site Add to Group \\n\", \n",
    "        elif row_curr == row_prev and count >=cluster_max:\n",
    "            # add to cluster pointed to by start\n",
    "            lsee.set_value(i,'clustereNb', start)\n",
    "            \n",
    "            if low_see:\n",
    "                print \"Case 2- OverFlow \\n\"\n",
    "        elif row_curr != row_prev and count <cluster_max:\n",
    "            # add to cluster pointed to by start\n",
    "            lsee.set_value(i,'clustereNb', start)\n",
    "            \n",
    "            if low_see:\n",
    "                print \"**************Case 3- New site Add to Group \\n\", \n",
    "        elif row_curr != row_prev and count >=cluster_max:\n",
    "            #create new cluster; add self; reset count and reset start pointer\n",
    "            clusterenb = lsee.get_value(i,'Genid')\n",
    "            start = int(clusterenb)\n",
    "            if low_see:\n",
    "                print \"start \", start, 'count ', count\n",
    "\n",
    "            count = 0\n",
    "            lsee.set_value(i,'clustereNb', start)\n",
    "            if low_see:\n",
    "                print \"start \", start, 'count ', count\n",
    "                print \"**************Case 4- New Group \\n\",\n",
    "            \n",
    "        else:\n",
    "            if True:\n",
    "                print 'Case 5***************'\n",
    "                print 'This should never be true'\n",
    "                print 'row_curr ', row_curr, 'row_prev ', row_prev, 'count ', count, 'i ', i\n",
    "        row_prev = row_curr\n",
    "    if low_see:\n",
    "        print 'Test cluster to use ', clusterenb, start, i\n",
    "    return (lsee)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simply pythonic way to set the clusereNb id  by eNBid\n",
    "\n",
    "def get_genid(grp):\n",
    "    value = grp.get_value(0,0,'Genid')\n",
    "    grp['clustereNb']= int(value)\n",
    "    return grp\n",
    "#lsee is the main dataframe now with the updated cluster eNb ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_df(inputFile):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import csv\n",
    "    # A Place to override the passed filename\n",
    "    filename = 'RM_MSA_LookUP.csv'\n",
    "    try:\n",
    "        with open(inputFile) as mapfile:\n",
    "            mapfile_df = pd.read_csv(mapfile,skipinitialspace=True,dtype=unicode)\n",
    "    except:\n",
    "            print \"something went wrong\"\n",
    "    return mapfile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clusterdist(lsee2,see):\n",
    "    #  2nd Attempt More pythonic way\n",
    "    see = True\n",
    "    low_see = False\n",
    "    import calc_distance\n",
    "    df_size = len(lsee2.index)\n",
    "    distance = 0.0\n",
    "\n",
    "\n",
    "    print \"Size of List \", (df_size)\n",
    "\n",
    "    for row in range(df_size):\n",
    "        clusterenb = lsee2.get_value(row,'clustereNb')\n",
    "        lat1 = lsee2.get_value(row,'Lat')\n",
    "        lon1 = lsee2.get_value(row,'Lon')\n",
    "        # Need to do a look up to find the clustereNb coordinates\n",
    "        # Find where pip is in the original dataframe  an index, there may be multiple instance take the first\n",
    "        index_list = lsee2.loc[lsee2['Genid'] ==clusterenb].index.tolist()\n",
    "        tcluster = int(index_list[0])\n",
    "\n",
    "        tlat2 = lsee2.loc[tcluster,['Lat']].values.tolist()\n",
    "        tlon2 = lsee2.loc[tcluster,['Lon']].values.tolist()\n",
    "        lat2 = float(tlat2[0])\n",
    "        lon2 = float(tlon2[0])\n",
    "        # Call the distance function\n",
    "        distance = calc_distance.get_dist_to_cell(lat1,lon1,lat2,lon2)\n",
    "        lsee2.set_value(row,'clusterdist',distance)\n",
    "\n",
    "        if low_see:\n",
    "            print 'row', row,'Distance in Km', distance,\n",
    "            print 'lat1 ','lon1 ', lat1, lon1,  'lat2 ', 'lon2 ', lat2, lon2  \n",
    "        if distance > 5.0:\n",
    "            print 'Distance in Km', distance,'clusterenb ', clusterenb,\" \" , row\n",
    "\n",
    "    return (lsee2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Functions to get values from the dataframes based on index\n",
    "def get_lon (df,test,see):\n",
    "\n",
    "    # Step 0 of 3\n",
    "    value_list = df[['Genid','Lon']].values.tolist()\n",
    "    # Ste 1 of 3 find the index to the first value 2nd column \n",
    "    value = value_list[test][1]\n",
    "    if see:\n",
    "        print 'get_lon: value ', value\n",
    "    # still in step 1:\n",
    "    lon_index = df.loc[df['Lon']==value].index.tolist()\n",
    "    if see:\n",
    "        print 'get_lon: lon_index ', lon_index\n",
    "\n",
    "    # Step 2 of 3\n",
    "    sindex = lon_index[0]\n",
    "    if see:\n",
    "        print 'get_lon: sindex', sindex\n",
    "    # Step 3A of 3\n",
    "    row_prev = df.loc[sindex,['Genid','Lon']].values.tolist()\n",
    "    if see:\n",
    "        print 'get_lon:  row_prev ', row_prev\n",
    "    return row_prev\n",
    "# Repeat to get the eNB id\n",
    "###################################################\n",
    "def get_enb (df,test,see):\n",
    "\n",
    "    # Step 0 of 3\n",
    "    # Aleady computed above no need to redo\n",
    "    value_list = df[['Genid','Lon']].values.tolist()\n",
    "    # Step 1 of 3 find the index to the first value 2nd column \n",
    "    value = value_list[test][0]\n",
    "    if see:\n",
    "        print 'get_enb: value ', value\n",
    "    # still in step 1:\n",
    "    geid_index = df.loc[df['Genid']==value].index.tolist()\n",
    "    if see:\n",
    "        print 'get_enb: lon_index ', geid_index\n",
    "\n",
    "    # Step 2 of 3\n",
    "    sindex = geid_index[0]\n",
    "    if see:\n",
    "        print 'get_enb: sindex', sindex\n",
    "    # Step 3A of 3\n",
    "    rowv = df.loc[sindex,['Genid']].values.tolist()\n",
    "    if see:\n",
    "        print 'get_enb:  rowv ', rowv\n",
    "    # let us try modifying a value\n",
    "    if see:\n",
    "        print df.get_value(sindex,'clustereNb')\n",
    "    return rowv, sindex\n",
    "\n",
    "#Writing to Dataframe\n",
    "\n",
    "#df.set_value(sindex,'clustereNb', 81414)\n",
    "#print 'New value ',df.get_value(sindex,'clustereNb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read in the data using Pandas Data Frames from a raw UTF-8 *.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "#Globally enable debug printing\n",
    "see = False\n",
    "#%matplotlib notebook\n",
    "inputFile = \"cellsummaryshort.csv\"\n",
    "inputFile = \"cellsummaryNYM.csv\"\n",
    "cluster_max = 100\n",
    "\n",
    "df = get_df(inputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in a list of Columns.\n",
    "list(df)\n",
    "pp = pprint.PrettyPrinter(depth=4, width =10)\n",
    "if see:\n",
    "    pp.pprint(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rename some very long column names\n",
    "df.rename(columns={'Number of Downlink Antennas':'Tx'}, inplace=True)\n",
    "df.rename(columns={'Number of Uplink Antennas':'Rx'}, inplace=True)\n",
    "# Downlink Bandwidth to DLBW\n",
    "df.rename(columns={ 'Downlink Bandwidth':'DLBW'}, inplace=True)\n",
    "# Cell Latitude and Cell Longitude to Lat Lon\n",
    "df.rename(columns={ 'Cell Latitude':'Lat'}, inplace=True)\n",
    "df.rename(columns={ 'Cell Longitude':'Lon'}, inplace=True)\n",
    "\n",
    "# get rid of spaces!!\n",
    "df.rename(columns={ 'Cell Id':'Cellid'}, inplace=True)\n",
    "df.rename(columns={ 'Global eNodeB ID':'Genid'}, inplace=True)\n",
    "df.rename(columns={ 'LTE Cell Name':'lteCellid'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#clean up Uplink Antennas and Downlink Bandwidth columns to be a number and more readable column\n",
    "df.replace('ulAntenna1',1, inplace=True)\n",
    "df.replace('ulAntenna2',2, inplace=True)\n",
    "df.replace('ulAntenna4',4, inplace=True)\n",
    "# We could transform these strings to numbers in the future, for now just identifying them is sufficient\n",
    "df.replace('n75-15MHz', '15MHz', inplace=True)\n",
    "df.replace('n50-10MHz', '10MHz', inplace=True)\n",
    "df.replace('n100-20MHz', '20MHz', inplace=True)\n",
    "\n",
    "\n",
    "# Compute the total number of unique eNBs\n",
    "\n",
    "count = df['Genid'].groupby(df['Genid']).unique()\n",
    "count = df['Genid'].unique()\n",
    "print \"Number of eNBs\",count.size\n",
    "\n",
    "\n",
    "#this may not be returning the correct values, the number of unique sites can not be \n",
    "# Greater than the total number eNBs!\n",
    "#countsite = pd.concat([df['Lat'],df['Lon']]).unique()\n",
    "countsite = np.unique(df[['Lon']])\n",
    "print \"Number of sites\", countsite.size\n",
    "max_enb =count.size\n",
    "\n",
    "# Compute the total number of unique Cells\n",
    "\n",
    "enb_df = pd.value_counts(df['Cellid'].values, sort=True)\n",
    "count = enb_df.values\n",
    "print ' Number of Cells = ',count.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort the data by lat and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort Rows by lat, long\n",
    "# Create a list\n",
    "cell_sort = []\n",
    "cell_sort = [ 'Lat', 'Lon']\n",
    "# Not used\n",
    "#df_loc_sort = df.sort(cell_sort)\n",
    "#df.sort(cell_sort, inplace=True)\n",
    "# Sorting by both Lat and Lon produce interesting results, so we will just choose Lon\n",
    "try:\n",
    "    df.sort(['Lon','Genid'], inplace=True)\n",
    "    df.reset_index(drop = True, inplace=True)\n",
    "    df= df.convert_objects(convert_numeric=True)\n",
    "except:\n",
    "    print 'There was an error sorting in place and converting objects to numerical values'\n",
    "\n",
    "if see:\n",
    "    df['Genid'].groupby(df['Cellid']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns in the data that are not relevant to the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This might change with a different formatted data set if the columns above change.\n",
    "ndf = df.drop(\n",
    " ['\\xef\\xbb\\xbfNetwork Element','eNB ePC Name',\n",
    "  'eNodeB Name',\n",
    " 'eNodeB Alias Name',\n",
    " 'eNodeB Admin State',\n",
    " 'PLMN Country Code',\n",
    " 'PLMN Network Code',\n",
    " 'Physical Cell Identity',\n",
    " 'LTE Cell Status',\n",
    " 'Running SW Version',\n",
    " 'Tracking Area',\n",
    " 'Cell Radius',\n",
    " 'Downlink EARFCN',\n",
    " 'Uplink EARFCN',\n",
    "  'Uplink Bandwidth',\n",
    " 'Downlink power',\n",
    " '700 MHz',\n",
    " '2x2 MIMO',\n",
    " '4x2 MIMO',\n",
    "  'Azimuth'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Columns to represent the cluster eNB and cluster id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add clustereNB and clusterdist columns\n",
    "#take the eNb id column and make a list\n",
    "eNb = []\n",
    "# One way to populate the clustereNb is to see it with the actual Global eNb Id\n",
    "eNb = ndf['Genid'].astype(int).tolist()\n",
    "# now make that list the initial clustereNb column\n",
    "ndf['clustereNb'] = pd.Series(eNb, index=ndf.index)\n",
    "# The preferred way is to use random numbers, but we need integers!!\n",
    "# Override if uncommended with random values.  Either way is fine.\n",
    "try:\n",
    "    # now make that list the initial clustereNb column\n",
    "    ndf['clustereNb'] = pd.Series(eNb, index=ndf.index)\n",
    "    ndf['clusterdist'] = pd.Series(np.random.randn(), index=ndf.index)\n",
    "\n",
    "    #ndf['clustereNb'] = pd.Series(np.random.randn(), index=ndf.index)\n",
    "    #ndf['clustereNb'] = pd.Series(np.random.randint(88888,high=99999), index=ndf.index)\n",
    "except:\n",
    "    print 'Random initialization Failed'\n",
    "\n",
    "if see:\n",
    "    print ndf[21:28][['Genid','clustereNb','clusterdist']]\n",
    "    print ndf[0:5][['Genid','clustereNb']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides us with a beginning list of cluster eNB locations equal to the same site. Below we update that list with first eNB in the group by location. Later we will replace the cluster ids with the actual cluster site locations based on N number of clusters combined together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temporarliy turning off assigning eNBid by locations\n",
    "#lsee= ndf.groupby(['Lon']).apply(get_genid)\n",
    "# it is import to keep the indexing of the DF correct or the clustering routine will fail\n",
    "lsee =ndf.copy(deep = True)\n",
    "lsee.reset_index(drop = False, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next executions set up variables to create a key for the locations and the cluster eNBs\n",
    "We will loop through the entire set of eNBs grouping by cluster_max to create our sample clusters of cluster_max size. The loop takes care to avoid splitting locations so in some cases the clusters may be slightly bigger than 100 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Temp overide over cluster max for testing\n",
    "import time\n",
    "see = 1; # Turn off printing in the function\n",
    "start_time = time.time()\n",
    "# Control whether to perform the long loop for creating clusters\n",
    "if False:\n",
    "    lsee2 = create_clusters(lsee,cluster_max,see)\n",
    "    #Now generate cluster distances\n",
    "    lsee2 = clusterdist(lsee2,see)\n",
    "else:\n",
    "    lsee2 = lsee.copy()\n",
    "\n",
    "count = lsee2['clustereNb'].unique()\n",
    "print count.size, 'Number of Unique Clusters of size ~=  ', cluster_max, time.time()- start_time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out to a file using the pandas to_excel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote  NYMCluster-100cell.xls  to directory in excel format\n"
     ]
    }
   ],
   "source": [
    "# First let's create a grouping that provides only the necessary data and unstacks the rows for excel\n",
    "#This grouping provides a count of cells per cluster with informaton on the antenna config + BW.\n",
    "grouped =lsee2[['Genid','Cellid','Rx','Tx','clustereNb','DLBW','Lat','Lon','clusterdist']].\\\n",
    "groupby(['clustereNb','Genid','DLBW','Rx','Tx','Lat','Lon','clusterdist']).size().reset_index(name='count')\n",
    "\n",
    "# Python and pandas requires you perform some operation to turn the groupedby DF into a regular DF. \n",
    "# So this is a dummy operation\n",
    "grouped.sum(inplace = False)\n",
    "\n",
    "# Build the file name to be used based on the number of clusters chosen\n",
    "filename = 'NYMCluster-' + str(cluster_max)+ 'cell.xls'\n",
    "try:\n",
    "    grouped.to_excel(filename, sheet_name='clusters')\n",
    "    print 'Wrote ', filename, \" to directory in excel format\"\n",
    "except:\n",
    "    print \"File writing didn't succeed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Resulting Before clustering \n",
      "      Genid  clustereNb       Lat       Lon\n",
      "4736  78778       78778  40.01162 -73.76309\n",
      " Resulting after clustering \n",
      "      Genid  clustereNb\n",
      "4736  78778       78778\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if see:\n",
    "    print ' Resulting Before clustering \\n',ndf[['Genid','clustereNb','Lat','Lon']][(ndf['Genid']==78778)]\n",
    "    print ' Resulting after clustering \\n',lsee2[['Genid','clustereNb']][(lsee2['clustereNb']==78778)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Madison Square Garden location as a reference point and compute the number of cells within X Km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Count =  225\n"
     ]
    }
   ],
   "source": [
    "# coordinates for MSG\n",
    "# 40.7505° N, 73.9934°\n",
    "# 40.750298,-73.993324\n",
    "import calc_distance\n",
    "df_size = len(lsee2.index)\n",
    "low_see = False\n",
    "count = 0\n",
    "msg_dist = .45\n",
    "lat_list = []\n",
    "lon_list = []\n",
    "\n",
    "for row in range(df_size):\n",
    "\n",
    "    lat1 = float(40.750298)\n",
    "    lon1 = float(-73.993324)\n",
    "    # We will just look for all eNBs in the list \n",
    "    tcluster = row\n",
    "\n",
    "    tlat2 = lsee2.loc[tcluster,['Lat']].values.tolist()\n",
    "    tlon2 = lsee2.loc[tcluster,['Lon']].values.tolist()\n",
    "    lat2 = float(tlat2[0])\n",
    "    lon2 = float(tlon2[0])\n",
    "    # Call the distance function\n",
    "    distance = calc_distance.get_dist_to_cell(lat1,lon1,lat2,lon2)\n",
    "    # Now just make a list of those that within some distance\n",
    "\n",
    "    if low_see:\n",
    "        print 'row', row,'Distance in Km', distance,\n",
    "        print 'lat1 ','lon1 ', lat1, lon1,  'lat2 ', 'lon2 ', lat2, lon2  \n",
    "        print 'Distance in Km', distance,' Count ', count\n",
    "    if distance  <= msg_dist:\n",
    "        count +=1\n",
    "        lat_list.append(lat2)\n",
    "        lon_list.append(lon2)\n",
    "\n",
    "\n",
    "if see:\n",
    "    print \"Final Count = \", count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "39\n",
      "(225, 2)\n",
      "KML writing to  MadisonSquareGarden-0.45cell.kml  succeeded\n",
      "Wrote  MadisonSquareGarden-0.45cell.xls  to directory in excel format\n"
     ]
    }
   ],
   "source": [
    "print len(lat_list)\n",
    "import simplekml\n",
    "#Add columns\n",
    "#ndf['clustereNb'] = pd.Series(eNb, index=ndf.index)\n",
    "\n",
    "#lsee2['clustereNb'].update(pd.Series(temp_list))\n",
    "#dfloc = pd.Series(np.random.randn(), index=['lat'])\n",
    "dfloc = pd.DataFrame(lat_list,columns=['lat'])\n",
    "dfloc['lon'] = pd.Series(lon_list, index=dfloc.index)\n",
    "countsize = dfloc['lon'].unique()\n",
    "print countsize.size\n",
    "#dfloc['lat'].update(pd.Series(lat_list))\n",
    "print dfloc.shape\n",
    " \n",
    "\n",
    "#Write to a file:\n",
    "# Build the file name to be used based on the number of clusters chosen\n",
    "kmlname = 'MadisonSquareGarden-' + str(msg_dist)+ 'cell.kml'\n",
    "kml = simplekml.Kml()\n",
    "dfloc.apply(lambda X: kml.newpoint(  coords=[( X[\"lon\"],X[\"lat\"])]) ,axis=1)\n",
    "try:\n",
    "    kml.save(path = kmlname)\n",
    "    print \"KML writing to \",kmlname, \" succeeded\"\n",
    "except:\n",
    "    print \"KML writing failed\"\n",
    "\n",
    "filename = 'MadisonSquareGarden-' + str(msg_dist)+ 'cell.xls'\n",
    "try:\n",
    "    dfloc.to_excel(filename, sheet_name='ToMSG')\n",
    "    print 'Wrote ', filename, \" to directory in excel format\"\n",
    "except:\n",
    "    print \"File writing didn't succeed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The remaining are just testing code fragments for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#40.54\t-74.149\n",
    "#40.54\t-74.1559\n",
    "distance = calc_distance.get_dist_to_cell(40.54,-74.149,40.54,-74.1559)\n",
    "if see:\n",
    "    print 'row', row,'Distance in Km', distance\n",
    "    print lsee2[46:58][['Genid','clustereNb','clusterdist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try a new create clusters\n",
    "ndf.sort('Lon', ascending = False, inplace=True)\n",
    "df = ndf.copy()\n",
    "df= df.groupby(['Lon']).apply(get_genid)\n",
    "df.reset_index(drop = False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    for name, group in df:\n",
    "        print \n",
    "        for row, col in group.iterrows():\n",
    "            gentemp = col['clustereNb']\n",
    "            print gentemp, type(gentemp),'count ', count\n",
    "            count+=1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now write the new clusters into a copy.  Unitl memory and space is an issue, we do this to be safe.\n",
    "# this is no longer used and could have copied the value incorrectly\n",
    "#lsee2 = lsee.copy(deep=True)\n",
    "#lsee2['clustereNb'].update(pd.Series(temp_list))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# better way to look up lat and long\n",
    "if False:\n",
    "\n",
    "    lat_list = lsee.loc[teNb,['Genid','Lat']].tolist()\n",
    "    lon_list = lsee.loc[teNb,['Genid','Lon']].tolist()\n",
    "    print lat_list, lon_list\n",
    "\n",
    "    lat_list = lsee.loc[test,['Genid','Lat']].tolist()\n",
    "    lon_list = lsee.loc[test,['Genid','Lon']].tolist()\n",
    "    print lat_list, lon_list\n",
    "\n",
    "#cluster = lsee2['Genid'] == cluster_list[40]\n",
    "#print lsee2[cluster].get_value(teNb,'Lon')\n",
    "#lsee2.iloc[['Genid']==79209]['clustereNb']\n",
    "#distance = calc_distance.get_dist_to_cell(lat1,lon1,lat2,lon2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First Attempt.The calc distance function should only require two sets of lat and longs  2nd Attempt\n",
    "see = True\n",
    "low_see = False\n",
    "import calc_distance\n",
    "df_size = len(lsee.index)\n",
    "\n",
    "#find lat and long for a eNb\n",
    "cluster_list = []\n",
    "temp_list = []\n",
    "# Create two list.  We actually want to create clusters counting locations, but use the clustereNB \n",
    "# column to keep up with clusters\n",
    "#Initialize\n",
    "\n",
    "cluster_list = lsee2[['Genid','clustereNb']].values.tolist()\n",
    "#Pick a test row\n",
    "# 31 is good\n",
    "test = 91\n",
    "# loop shoot\n",
    "print len(cluster_list)\n",
    "for row in range(1,len(cluster_list)):\n",
    "    test = row\n",
    "    clusterenb = lsee.get_value(i,'Genid')\n",
    "\n",
    "    # Get the enB Id from the test row\n",
    "    pip = cluster_list[test]\n",
    "    if low_see:\n",
    "        print 'pip[1] _test_cluster this is an eNbId ', pip[1]\n",
    "        print 'pip [0] is an eNbId on that same row ', pip[0]\n",
    "\n",
    "    # Find where pip is in the original dataframe  an index, there may be multiple instance take the first\n",
    "    index_list = lsee2.loc[lsee2['Genid'] ==pip[1]].index.tolist()\n",
    "    tcluster = int(index_list[0])\n",
    "    if low_see:\n",
    "        print 'Test row for eNB selection ',pip[0],test, 'Cluster row location ', index_list\n",
    "    # take that reference and get information\n",
    "\n",
    "\n",
    "    # now get the referenc for eNB\n",
    "    index_list = lsee2.loc[lsee2['Genid'] ==pip[0]].index.tolist()\n",
    "    teNb = int(index_list[0])\n",
    "    if low_see:\n",
    "        print pip[1], ' teNb ', teNb\n",
    "        print pip[0], ' tcluster ', tcluster, '\\n'\n",
    "    if low_see:\n",
    "        print lsee2.loc[teNb,['Genid','Lat','Lon','clustereNb']].tolist()\n",
    "        print lsee2.loc[tcluster,['Genid','Lat','Lon','clustereNb']].tolist()\n",
    "   \n",
    "    tlat1 = lsee2.loc[teNb,['Lat']].values.tolist()\n",
    "    tlon1 = lsee2.loc[teNb,['Lon']].values.tolist()\n",
    "    lat1 = float(tlat1[0])\n",
    "    lon1 = float(tlon1[0])\n",
    "\n",
    "    tlat2 = lsee2.loc[tcluster,['Lat']].values.tolist()\n",
    "    tlon2 = lsee2.loc[tcluster,['Lon']].values.tolist()\n",
    "    lat2 = float(tlat2[0])\n",
    "    lon2 = float(tlon2[0])\n",
    "    if low_see:\n",
    "        print float(tlat1[0])\n",
    "        print float(tlon1[0])\n",
    "        print float(tlat2[0])\n",
    "        print float(tlon2[0])\n",
    "\n",
    "\n",
    "    distance = calc_distance.get_dist_to_cell(lat1,lon1,lat2,lon2)\n",
    "    if see:\n",
    "        print 'row', row,'Distance in Km', distance,\n",
    "        print 'lat1 ','lon1 ', lat1, lon1,  'lat2 ', 'lon2 ', lat2, lon2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of using a list to create key columns hard to pass though\n",
    "key_col = []\n",
    "key_col = [ 'Global eNodeB ID',\n",
    " 'Cell Id',\n",
    " 'Sector',\n",
    " 'Physical Cell Identity',\n",
    " 'Cell Latitude',\n",
    " 'Cell Longitude']\n",
    "key_col = [ 'Global eNodeB ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lsee2 = lsee.copy()\n",
    "# Fragment to read a list into a dataframe.\n",
    "\n",
    "lsee2['clustereNb'].update(pd.Series(temp_list))\n",
    "# A method to check if the orginal cluster changed.  The new cell may not show up in the resulting clusters.\n",
    "if False:\n",
    "    print 'Original \\n', ndf[(ndf['Genid']==79209)]\n",
    "    print ' Resulting after clustering \\n',lsee2[(lsee2['Genid']==79209)]\n",
    " \n",
    "\n",
    "\n",
    "grouped =lsee2[['Genid','Cellid','Tx','Rx','clustereNb','DLBW']].groupby(['clustereNb','Tx','Rx','DLBW'], as_index=False)\n",
    "#lsee2[['Genid','Cellid','Tx','Rx','clustereNb','DLBW']].groupby(['clustereNb','Tx','Rx','DLBW']).count().unstack().unstack()\n",
    "\n",
    "#lsee2[['Genid','Cellid','clustereNb','DLBW']].groupby(['clustereNb','Genid','DLBW']).count()\n",
    "\n",
    "\n",
    "table = pd.pivot_table(lsee2, values='Tx',index=['clustereNb'], columns=['DLBW'], aggfunc=np.sum)\n",
    "table = pd.pivot_table(lsee2, values ='Rx',index=['clustereNb'], columns=['DLBW'])\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This version is defunct and is incorrect\n",
    "def create_clusters1(lsee, cluster_max):\n",
    "    \n",
    "    #print lsee[(lsee['clustereNb']==83209)]\n",
    "    # Create a Cluster key\n",
    "    cluster_list = []\n",
    "    temp_list = []\n",
    "    # Create two list.  We actually want to create clusters counting locations, but use the clustereNB \n",
    "    # column to keep up with clusters\n",
    "    #Initialize\n",
    "    \n",
    "    cluster_list = lsee['clustereNb'].tolist()\n",
    "    loc_list = lsee['Lon'].tolist()\n",
    "\n",
    "    count = 0\n",
    "    if not cluster_max:\n",
    "        cluster_max = 100\n",
    "    print cluster_max\n",
    "    \n",
    "    row_prev = loc_list[0]\n",
    "    row_curr = loc_list[0]\n",
    "\n",
    "    temp_list =  np.copy(cluster_list)\n",
    "\n",
    "    #print 'First Group @ ', tick, row_prev\n",
    "\n",
    "    # Loop to assign cluster keys every cluster_max groups unless they are the same location\n",
    "    for i, row in enumerate(loc_list):\n",
    "        rowv = cluster_list[i]\n",
    "        #Should not just write before checking anything!!\n",
    "        #temp_list[i] = rowv\n",
    "        count +=1\n",
    "        # This is the actual value vs index\n",
    "        row_curr = row\n",
    "        # We check that the value doesn't equal the previous one because we need to keep eNBs together\n",
    "        # If we are on a different eNB and we have maxed the cluster then create a new cluster\n",
    "        if row_curr != row_prev and count > cluster_max:\n",
    "            #print 'Next Group @ ', i, row, row_curr, row_prev, 'Count ', count\n",
    "            temp_list[i] = rowv\n",
    "            count = 0\n",
    "            row_prev = row_curr\n",
    "\n",
    "        elif row_curr == row_prev:\n",
    "            #print 'overflow', row,i, row_curr, row_prev, 'Count ', count\n",
    "            temp_list[i] = rowv\n",
    "            count =0\n",
    "        else:\n",
    "            temp_list[i] = temp_list[i-1]\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Careful this is the second version\n",
    "def create_clusters2(lsee_in, cluster_max,see):\n",
    "    # Initialize variables and set up first comparison\n",
    "    lsee = lsee_in.copy()\n",
    "    count = 0\n",
    "    low_see = 0\n",
    "    start =0\n",
    "    if not cluster_max:\n",
    "        cluster_max = 100\n",
    "    if see:\n",
    "        print cluster_max\n",
    "    loc_list = df[['Genid','Lon']].values.tolist()\n",
    "    # Above row = tupple  = [enid , lon_value]\n",
    "    loc_list = df[['Lon']].values.tolist()\n",
    "    # Above row = lon_value\n",
    "\n",
    "    \n",
    "    #row_prev = loc_list[0]\n",
    "    #row_curr = loc_list[0]\n",
    "    # Use row_prev from new code with test = 0!\n",
    "    row_prev_ = get_lon(lsee,0,low_see)\n",
    "    row_prev = row_prev_[1]\n",
    "    \n",
    "    # Don't do something like this ever again!!!\n",
    "    #temp_list =  np.copy(cluster_list)\n",
    "\n",
    "    # Loop to assign cluster keys every cluster_max groups unless they are the same location\n",
    "    for i, row in enumerate(loc_list):\n",
    "        #Should not just write before checking anything!!\n",
    "        #temp_list[i] = rowv\n",
    "        rowv,sindex = get_enb(lsee,i,low_see)\n",
    "        lsee.set_value(sindex,'clustereNb', rowv[0])\n",
    "\n",
    "        # This is the actual value vs index\n",
    "        row_curr_ = get_lon(lsee,i,low_see)\n",
    "        row_curr = float(row_curr_[1])\n",
    "        # We check that the value doesn't equal the previous one because we need to keep eNBs together\n",
    "        # If we are on a different eNB and we have maxed the cluster then create a new cluster\n",
    "        if row_curr != row_prev and count >= cluster_max:\n",
    "            # in this condition we stay in the same cluster\n",
    "            if see:\n",
    "                print 'Next Group @ row ',row,'**i', i,'start ', start, 'row_curr ', \\\n",
    "                row_curr,'row_prev ', row_prev, 'Count ', count\n",
    "            #temp_list[i] = rowv\n",
    "            rowv,sindex = get_enb(lsee,i,low_see)\n",
    "            if see:\n",
    "                print 'value at count ',lsee.get_value(count,'clustereNb')\n",
    "                print 'old value ',int(rowv[0])\n",
    "            # Now right the value of the last group before proceeding\n",
    "            rowv,sindex = get_enb(lsee,i,low_see)\n",
    "            value = int(rowv[0])\n",
    "            lsee.set_value(i,'clustereNb', value)\n",
    "            if see:\n",
    "                rowv,sindex = get_enb(lsee,i,low_see)\n",
    "                print 'New value ',int(rowv[0])\n",
    "            count = 0\n",
    "            start = i\n",
    "            if see:\n",
    "                print 'Start ', start\n",
    "            row_curr_ = get_lon(lsee,i,low_see)\n",
    "            row_prev = float(row_curr_[1])\n",
    "        if row_curr == row_prev and count < cluster_max:\n",
    "            if see:\n",
    "                print 'create_clusters: overflow  row', row,'**start ', start,'i' ,\\\n",
    "                i,'row_curr ', row_curr, row_prev, 'Count ', count\n",
    "            #temp_list[i] = rowv\n",
    "            rowv,sindex = get_enb(lsee,i,low_see)\n",
    "            if see:\n",
    "                print 'old value ',rowv[0]\n",
    "            \n",
    "            rowv,sindex = get_enb(lsee,start,low_see)\n",
    "            value = int(rowv[0])\n",
    "            lsee.set_value(i,'clustereNb', value)\n",
    "            if see:\n",
    "                print 'New value ',int(rowv[0])\n",
    "            count +=1\n",
    "        if row_curr != row_prev:\n",
    "            if see:\n",
    "                print 'Continue in group: row', row,'**start ',start, 'i ',i,'row_curr ', \\\n",
    "                row_curr,'row_prev ',row_prev,'Count ', count\n",
    "            rowv,sindex = get_enb(lsee,i,low_see)\n",
    "            if see:\n",
    "                print 'old value ',int(rowv[0])\n",
    "            rowv,sindex = get_enb(lsee,start,low_see)\n",
    "            \n",
    "            value = int(rowv[0])\n",
    "            lsee.set_value(i,'clustereNb', value)\n",
    "            \n",
    "            if see:\n",
    "                print 'New value ',int(rowv[0])\n",
    "            row_prev = row_curr\n",
    "            count +=1\n",
    "        else:\n",
    "            if see:\n",
    "                print 'Count ', count, ' We missed you i', i,'row_curr', row_curr,\\\n",
    "                'row_prev',row_prev, 'start ', start\n",
    "    if see:\n",
    "        count = lsee['clustereNb'].unique()\n",
    "    print count.size, 'Number of Unique Clusters of size ~=  ', cluster_max\n",
    "    return (lsee)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
