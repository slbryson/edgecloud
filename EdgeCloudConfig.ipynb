{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Function will reformat and analyse market data from RAVs in order to dimension the Edge Cloud Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Careful this is the third version\n",
    "def create_clusters(lsee_in, cluster_max,see):\n",
    "    # Initialize variables and set up first comparison\n",
    "    lsee = lsee_in.copy()\n",
    "    # We will use this variable to count towards cluster max size\n",
    "    count = 0\n",
    "    # Use low_see to turn off printing in the sub-routines, but leave it on here\n",
    "    low_see = False\n",
    "    # Use this variable to record the eNB id of the cluster\n",
    "    clusterenb = lsee.get_value(0,'Genid')\n",
    "    start = int(clusterenb)\n",
    "    if see:\n",
    "        print 'Starting clustereNb ', start\n",
    "    if not cluster_max:\n",
    "        cluster_max = 100\n",
    "    if see:\n",
    "        print cluster_max\n",
    "        # Loop to assign cluster keys every cluster_max groups unless they are the same location\n",
    "    row_prev_ = get_lon(lsee,0,low_see)\n",
    "    row_prev = float(row_prev_[1])\n",
    "    ##################################################\n",
    "\n",
    "    df_size = len(lsee.index)\n",
    "    \n",
    "    for i in range(df_size):\n",
    "        count +=1\n",
    "        row_curr_ = get_lon(lsee,i,low_see)\n",
    "        row_curr = float(row_curr_[1])\n",
    "        #rowv_,sindex = get_enb(lsee,i,low_see)\n",
    "        #rowv = int(rowv_[0])\n",
    "        clusterenb = lsee.get_value(i,'clustereNb')\n",
    "        ##################################################\n",
    "        # We could get the distance of the current row to the proposed cluster \n",
    "        # If the distance is beyond a limit, we could force a new cluster, this is overkill since\n",
    "        # others will have a k-means clustering algorithm.\n",
    "        ##################################################\n",
    "        # Check 4 cases \n",
    "        if row_curr == row_prev and count <cluster_max:\n",
    "            #add to cluster by taking genid and setting to clusterenb;\n",
    "            lsee.set_value(i,'clustereNb', start)\n",
    "\n",
    "            if low_see:\n",
    "                print \"Case 1- Same Site Add to Group \\n\", \n",
    "        elif row_curr == row_prev and count >=cluster_max:\n",
    "            # add to cluster pointed to by start\n",
    "            lsee.set_value(i,'clustereNb', start)\n",
    "            \n",
    "            if low_see:\n",
    "                print \"Case 2- OverFlow \\n\"\n",
    "        elif row_curr != row_prev and count <cluster_max:\n",
    "            # add to cluster pointed to by start\n",
    "            lsee.set_value(i,'clustereNb', start)\n",
    "            \n",
    "            if low_see:\n",
    "                print \"**************Case 3- New site Add to Group \\n\", \n",
    "        elif row_curr != row_prev and count >=cluster_max:\n",
    "            #create new cluster; add self; reset count and reset start pointer\n",
    "            clusterenb = lsee.get_value(i,'Genid')\n",
    "            start = int(clusterenb)\n",
    "            if low_see:\n",
    "                print \"start \", start, 'count ', count\n",
    "\n",
    "            count = 0\n",
    "            lsee.set_value(i,'clustereNb', start)\n",
    "            if low_see:\n",
    "                print \"start \", start, 'count ', count\n",
    "                print \"**************Case 4- New Group \\n\",\n",
    "            \n",
    "        else:\n",
    "            if True:\n",
    "                print 'Case 5***************'\n",
    "                print 'This should never be true'\n",
    "                print 'row_curr ', row_curr, 'row_prev ', row_prev, 'count ', count, 'i ', i\n",
    "        row_prev = row_curr\n",
    "    if low_see:\n",
    "        print 'Test cluster to use ', clusterenb, start, i\n",
    "    return (lsee)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simply pythonic way to set the clusereNb id  by eNBid\n",
    "\n",
    "def get_genid(grp):\n",
    "    value = grp.get_value(0,0,'Genid')\n",
    "    grp['clustereNb']= int(value)\n",
    "    return grp\n",
    "#lsee is the main dataframe now with the updated cluster eNb ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_df(inputFile):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import csv\n",
    "    # A Place to override the passed filename\n",
    "    filename = 'RM_MSA_LookUP.csv'\n",
    "    try:\n",
    "        with open(inputFile) as mapfile:\n",
    "            mapfile_df = pd.read_csv(mapfile,skipinitialspace=True,dtype=unicode)\n",
    "    except:\n",
    "            print \"something went wrong\"\n",
    "    return mapfile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clusterdist(lsee2,see):\n",
    "    #  2nd Attempt More pythonic way\n",
    "    see = False\n",
    "    low_see = False\n",
    "    import calc_distance\n",
    "    df_size = len(lsee2.index)\n",
    "    distance = 0.0\n",
    "    count = 0\n",
    "\n",
    "    print \"Size of List \", (df_size)\n",
    "\n",
    "    for row in range(df_size):\n",
    "        clusterenb = lsee2.get_value(row,'clustereNb')\n",
    "        lat1 = lsee2.get_value(row,'Lat')\n",
    "        lon1 = lsee2.get_value(row,'Lon')\n",
    "        # Need to do a look up to find the clustereNb coordinates\n",
    "        # Find where pip is in the original dataframe  an index, there may be multiple instance take the first\n",
    "        index_list = lsee2.loc[lsee2['Genid'] ==clusterenb].index.tolist()\n",
    "        tcluster = int(index_list[0])\n",
    "\n",
    "        tlat2 = lsee2.loc[tcluster,['Lat']].values.tolist()\n",
    "        tlon2 = lsee2.loc[tcluster,['Lon']].values.tolist()\n",
    "        lat2 = float(tlat2[0])\n",
    "        lon2 = float(tlon2[0])\n",
    "        # Call the distance function\n",
    "        distance = calc_distance.get_dist_to_cell(lat1,lon1,lat2,lon2)\n",
    "        lsee2.set_value(row,'clusterdist',distance)\n",
    "\n",
    "        if low_see:\n",
    "            print 'row', row,'Distance in Km', distance,\n",
    "            print 'lat1 ','lon1 ', lat1, lon1,  'lat2 ', 'lon2 ', lat2, lon2  \n",
    "        if distance > 5.0:\n",
    "            count +=1\n",
    "            if see:\n",
    "                print 'Distance in Km', distance,'clusterenb ', clusterenb,\" \" , row\n",
    "    print 'sites > 5km = ', count\n",
    "    return (lsee2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Functions to get values from the dataframes based on index\n",
    "def get_lon (df,test,see):\n",
    "\n",
    "    # Step 0 of 3\n",
    "    value_list = df[['Genid','Lon']].values.tolist()\n",
    "    # Ste 1 of 3 find the index to the first value 2nd column \n",
    "    value = value_list[test][1]\n",
    "    if see:\n",
    "        print 'get_lon: value ', value\n",
    "    # still in step 1:\n",
    "    lon_index = df.loc[df['Lon']==value].index.tolist()\n",
    "    if see:\n",
    "        print 'get_lon: lon_index ', lon_index\n",
    "\n",
    "    # Step 2 of 3\n",
    "    sindex = lon_index[0]\n",
    "    if see:\n",
    "        print 'get_lon: sindex', sindex\n",
    "    # Step 3A of 3\n",
    "    row_prev = df.loc[sindex,['Genid','Lon']].values.tolist()\n",
    "    if see:\n",
    "        print 'get_lon:  row_prev ', row_prev\n",
    "    return row_prev\n",
    "# Repeat to get the eNB id\n",
    "###################################################\n",
    "def get_enb (df,test,see):\n",
    "\n",
    "    # Step 0 of 3\n",
    "    # Aleady computed above no need to redo\n",
    "    value_list = df[['Genid','Lon']].values.tolist()\n",
    "    # Step 1 of 3 find the index to the first value 2nd column \n",
    "    value = value_list[test][0]\n",
    "    if see:\n",
    "        print 'get_enb: value ', value\n",
    "    # still in step 1:\n",
    "    geid_index = df.loc[df['Genid']==value].index.tolist()\n",
    "    if see:\n",
    "        print 'get_enb: lon_index ', geid_index\n",
    "\n",
    "    # Step 2 of 3\n",
    "    sindex = geid_index[0]\n",
    "    if see:\n",
    "        print 'get_enb: sindex', sindex\n",
    "    # Step 3A of 3\n",
    "    rowv = df.loc[sindex,['Genid']].values.tolist()\n",
    "    if see:\n",
    "        print 'get_enb:  rowv ', rowv\n",
    "    # let us try modifying a value\n",
    "    if see:\n",
    "        print df.get_value(sindex,'clustereNb')\n",
    "    return rowv, sindex\n",
    "\n",
    "#Writing to Dataframe\n",
    "\n",
    "#df.set_value(sindex,'clustereNb', 81414)\n",
    "#print 'New value ',df.get_value(sindex,'clustereNb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read in the data using Pandas Data Frames from a raw UTF-8 *.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "#Globally enable debug printing\n",
    "see = False\n",
    "#%matplotlib notebook\n",
    "inputFile = \"cellsummaryshort.csv\"\n",
    "inputFile = \"cellsummaryNYM.csv\"\n",
    "cluster_max = int(256)\n",
    "\n",
    "df = get_df(inputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in a list of Columns.\n",
    "list(df)\n",
    "pp = pprint.PrettyPrinter(depth=4, width =10)\n",
    "if see:\n",
    "    pp.pprint(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of eNBs 3638\n",
      "Number of sites 3038\n",
      " Number of Cells =  18780\n"
     ]
    }
   ],
   "source": [
    "#rename some very long column names\n",
    "df.rename(columns={'Number of Downlink Antennas':'Tx'}, inplace=True)\n",
    "df.rename(columns={'Number of Uplink Antennas':'Rx'}, inplace=True)\n",
    "# Downlink Bandwidth to DLBW\n",
    "df.rename(columns={ 'Downlink Bandwidth':'DLBW'}, inplace=True)\n",
    "# Cell Latitude and Cell Longitude to Lat Lon\n",
    "df.rename(columns={ 'Cell Latitude':'Lat'}, inplace=True)\n",
    "df.rename(columns={ 'Cell Longitude':'Lon'}, inplace=True)\n",
    "\n",
    "# get rid of spaces!!\n",
    "df.rename(columns={ 'Cell Id':'Cellid'}, inplace=True)\n",
    "df.rename(columns={ 'Global eNodeB ID':'Genid'}, inplace=True)\n",
    "df.rename(columns={ 'LTE Cell Name':'lteCellid'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#clean up Uplink Antennas and Downlink Bandwidth columns to be a number and more readable column\n",
    "df.replace('ulAntenna1',1, inplace=True)\n",
    "df.replace('ulAntenna2',2, inplace=True)\n",
    "df.replace('ulAntenna4',4, inplace=True)\n",
    "# We could transform these strings to numbers in the future, for now just identifying them is sufficient\n",
    "df.replace('n75-15MHz', '15MHz', inplace=True)\n",
    "df.replace('n50-10MHz', '10MHz', inplace=True)\n",
    "df.replace('n100-20MHz', '20MHz', inplace=True)\n",
    "\n",
    "\n",
    "# Compute the total number of unique eNBs\n",
    "\n",
    "count = df['Genid'].groupby(df['Genid']).unique()\n",
    "#count = df['Genid'].unique()\n",
    "print \"Number of eNBs\",count.size\n",
    "\n",
    "\n",
    "#this may not be returning the correct values, the number of unique sites can not be \n",
    "# Greater than the total number eNBs!\n",
    "#countsite = pd.concat([df['Lat'],df['Lon']]).unique()\n",
    "countsite = np.unique(df[['Lat']])\n",
    "print \"Number of sites\", countsite.size\n",
    "max_enb =count.size\n",
    "\n",
    "# Compute the total number of unique Cells\n",
    "\n",
    "enb_df = pd.value_counts(df['Cellid'].values, sort=True)\n",
    "count = enb_df.values\n",
    "print ' Number of Cells = ',count.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort the data by lat and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort Rows by lat, long\n",
    "# Create a list\n",
    "cell_sort = []\n",
    "cell_sort = [ 'Lat', 'Lon']\n",
    "# Not used\n",
    "#df_loc_sort = df.sort(cell_sort)\n",
    "#df.sort(cell_sort, inplace=True)\n",
    "# Sorting by both Lat and Lon produce interesting results, so we will just choose Lon\n",
    "try:\n",
    "    df.sort(['Lon','Genid'], inplace=True)\n",
    "    df.reset_index(drop = True, inplace=True)\n",
    "    df= df.convert_objects(convert_numeric=True)\n",
    "except:\n",
    "    print 'There was an error sorting in place and converting objects to numerical values'\n",
    "\n",
    "if see:\n",
    "    df['Genid'].groupby(df['Cellid']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns in the data that are not relevant to the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This might change with a different formatted data set if the columns above change.\n",
    "ndf = df.drop(\n",
    " ['\\xef\\xbb\\xbfNetwork Element','eNB ePC Name',\n",
    "  'eNodeB Name',\n",
    " 'eNodeB Alias Name',\n",
    " 'eNodeB Admin State',\n",
    " 'PLMN Country Code',\n",
    " 'PLMN Network Code',\n",
    " 'Physical Cell Identity',\n",
    " 'LTE Cell Status',\n",
    " 'Running SW Version',\n",
    " 'Tracking Area',\n",
    " 'Cell Radius',\n",
    " 'Downlink EARFCN',\n",
    " 'Uplink EARFCN',\n",
    "  'Uplink Bandwidth',\n",
    " 'Downlink power',\n",
    " '700 MHz',\n",
    " '2x2 MIMO',\n",
    " '4x2 MIMO',\n",
    "  'Azimuth'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Columns to represent the cluster eNB and cluster id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add clustereNB and clusterdist columns\n",
    "#take the eNb id column and make a list\n",
    "eNb = []\n",
    "# One way to populate the clustereNb is to see it with the actual Global eNb Id\n",
    "eNb = ndf['Genid'].astype(int).tolist()\n",
    "# now make that list the initial clustereNb column\n",
    "ndf['clustereNb'] = pd.Series(eNb, index=ndf.index)\n",
    "# The preferred way is to use random numbers, but we need integers!!\n",
    "# Override if uncommended with random values.  Either way is fine.\n",
    "try:\n",
    "    # now make that list the initial clustereNb column\n",
    "    ndf['clustereNb'] = pd.Series(eNb, index=ndf.index)\n",
    "    ndf['clusterdist'] = pd.Series(np.random.randn(), index=ndf.index)\n",
    "\n",
    "    #ndf['clustereNb'] = pd.Series(np.random.randn(), index=ndf.index)\n",
    "    #ndf['clustereNb'] = pd.Series(np.random.randint(88888,high=99999), index=ndf.index)\n",
    "except:\n",
    "    print 'Random initialization Failed'\n",
    "\n",
    "if see:\n",
    "    print ndf[21:28][['Genid','clustereNb','clusterdist']]\n",
    "    print ndf[0:5][['Genid','clustereNb']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides us with a beginning list of cluster eNB locations equal to the same site. Below we update that list with first eNB in the group by location. Later we will replace the cluster ids with the actual cluster site locations based on N number of clusters combined together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temporarliy turning off assigning eNBid by locations\n",
    "#lsee= ndf.groupby(['Lon']).apply(get_genid)\n",
    "# it is import to keep the indexing of the DF correct or the clustering routine will fail\n",
    "lsee =ndf.copy(deep = True)\n",
    "lsee.reset_index(drop = False, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next executions set up variables to create a key for the locations and the cluster eNBs\n",
    "We will loop through the entire set of eNBs grouping by cluster_max to create our sample clusters of cluster_max size. The loop takes care to avoid splitting locations so in some cases the clusters may be slightly bigger than 100 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of List  18780\n",
      "sites > 5km =  12672\n",
      "71 Number of Unique Clusters of size ~=   256 208.319000006\n"
     ]
    }
   ],
   "source": [
    "# Temp overide over cluster max for testing\n",
    "import time\n",
    "see = 0; # Turn off printing in the function\n",
    "start_time = time.time()\n",
    "# Control whether to perform the long loop for creating clusters\n",
    "if True:\n",
    "    lsee2 = create_clusters(lsee,cluster_max,see)\n",
    "    #Now generate cluster distances\n",
    "    lsee2 = clusterdist(lsee2,see)\n",
    "else:\n",
    "    lsee2 = lsee.copy()\n",
    "\n",
    "count = lsee2['clustereNb'].unique()\n",
    "print count.size, 'Number of Unique Clusters of size ~=  ', cluster_max, time.time()- start_time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if see:\n",
    "    print ' Resulting Before clustering \\n',ndf[['Genid','clustereNb','Lat','Lon']][(ndf['Genid']==78778)]\n",
    "    print ' Resulting after clustering \\n',lsee2[['Genid','clustereNb']][(lsee2['clustereNb']==78778)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out to a file using the pandas to_excel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote  NYMCluster-100cell.xls  to directory in excel format\n"
     ]
    }
   ],
   "source": [
    "# First let's create a grouping that provides only the necessary data and unstacks the rows for excel\n",
    "#This grouping provides a count of cells per cluster with informaton on the antenna config + BW.\n",
    "grouped =lsee2[['Genid','Cellid','Rx','Tx','clustereNb','DLBW','Lat','Lon','clusterdist']].\\\n",
    "groupby(['clustereNb','Genid','DLBW','Rx','Tx','Lat','Lon','clusterdist']).size().reset_index(name='count')\n",
    "\n",
    "# Python and pandas requires you perform some operation to turn the groupedby DF into a regular DF. \n",
    "# So this is a dummy operation\n",
    "grouped.sum(inplace = False)\n",
    "\n",
    "# Build the file name to be used based on the number of clusters chosen\n",
    "filename = 'NYMCluster-' + str(cluster_max)+ 'cell.xls'\n",
    "try:\n",
    "    grouped.to_excel(filename, sheet_name='clusters')\n",
    "    print 'Wrote ', filename, \" to directory in excel format\"\n",
    "except:\n",
    "    print \"File writing didn't succeed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
